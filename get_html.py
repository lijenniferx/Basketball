##### the following script scrapes html generated by javascript
##### It gets the html from the website, then saves it to disk
#### it has to be saved, because otherwise reason Canopy gets really slow after the scraping. I don't know why.
#### Note: the code below is mostly borrowed from http://josechristian.com/2013/10/14/scraping-html-generated-by-javascript-python/, with slight modifications by me.


import sys
from PySide.QtGui import *
from PySide.QtCore import *
from PySide.QtWebKit import *

def save_html(url):

    
    class Render(QWebPage):
        def __init__(self, url):
    
            try:
                self.app = QApplication(sys.argv)
            except RuntimeError:  ### QApplication already exists
                self.app=QApplication.instance()
    
            QWebPage.__init__(self)
            self.loadFinished.connect(self._loadFinished)
            self.mainFrame().load(QUrl(url))
            self.app.exec_()
    
        def _loadFinished(self, result):
            self.frame = self.mainFrame()
            self.app.quit()
    
    def getHtml(str_url):
        r_html = Render(str_url)
        html = r_html.frame.toHtml()
    
        return html
    
    html=getHtml(url)

    ##############
    ### saving
    ###########

    f = open(url[-5:]+'.html','w')
    f.write(html.encode('utf-8'))
    f.close()




##########################################
#### Parsing the data from the html #####
#########################################
from bs4 import BeautifulSoup
import re

#### base url (http://wvustats.com/mbasketball/) saved as basketball.html 
html=open('basketball.html','r')
soup=BeautifulSoup(html.read(),'lxml')

#####################################
##### getting all of the relevant game links, saving as html.
###################################
games=soup.body.find_all('a',{'href':re.compile('http://wvustats.com/mbasketball/game/*')}) 
game_links=[x['href'] for x in games]

for links in game_links:
    save_html(links)
    